{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12716504,"sourceType":"datasetVersion","datasetId":8037313}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom transformers import RobertaTokenizer, RobertaForSequenceClassification\nfrom torch.optim import AdamW\nfrom sklearn.metrics import mean_squared_error\nfrom tqdm.auto import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-13T02:36:25.629033Z","iopub.execute_input":"2025-08-13T02:36:25.629279Z","iopub.status.idle":"2025-08-13T02:37:01.092044Z","shell.execute_reply.started":"2025-08-13T02:36:25.629256Z","shell.execute_reply":"2025-08-13T02:37:01.091213Z"}},"outputs":[{"name":"stderr","text":"2025-08-13 02:36:45.008060: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1755052605.359387      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1755052605.455949      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# --- 1. Muat data ---\nprint(\"--- Memuat Data ---\")\ndf_train = pd.read_csv('/kaggle/input/bdc-dataset/df_train (1).csv')\ndf_test = pd.read_csv('/kaggle/input/bdc-dataset/df_test (1).csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T02:37:01.093146Z","iopub.execute_input":"2025-08-13T02:37:01.093627Z","iopub.status.idle":"2025-08-13T02:37:01.579132Z","shell.execute_reply.started":"2025-08-13T02:37:01.093609Z","shell.execute_reply":"2025-08-13T02:37:01.578344Z"}},"outputs":[{"name":"stdout","text":"--- Memuat Data ---\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"df_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T02:37:01.579855Z","iopub.execute_input":"2025-08-13T02:37:01.580132Z","iopub.status.idle":"2025-08-13T02:37:01.619140Z","shell.execute_reply.started":"2025-08-13T02:37:01.580105Z","shell.execute_reply":"2025-08-13T02:37:01.618176Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                                 prompt  \\\n0     Young people who commit crimes should be treat...   \n1     Young people who commit crimes should be treat...   \n2     Young people who commit crimes should be treat...   \n3     Young people who commit crimes should be treat...   \n4     Young people who commit crimes should be treat...   \n...                                                 ...   \n9907  The best way to teach children to cooperate is...   \n9908  The best way to teach children to cooperate is...   \n9909  The best way to teach children to cooperate is...   \n9910  In today's world, people spend a lot of money ...   \n9911  Some people think the main purpose of schools ...   \n\n                                                  essay  task_achievement  \\\n0     Deciding to choose among the potential ways of...               7.0   \n1     In this modern era, youngsters who commit offe...               7.0   \n2     In this modern era, youngsters who commit offe...               6.0   \n3     It is suggested that punishments for immature ...               7.5   \n4     There is a controversial dispute about whether...               6.5   \n...                                                 ...               ...   \n9907  It is proved that sports activities at school ...               7.0   \n9908  Most people suggest that the prime way to teac...               7.0   \n9909  Few argue that, the best way is teachers train...               4.0   \n9910  Nowadays people tend to invest huge amounts of...               6.5   \n9911  The role of schools and the education system a...               7.0   \n\n      coherence_and_cohesion  lexical_resource  grammatical_range  \n0                        7.0               6.5                6.5  \n1                        7.0               7.0                7.0  \n2                        5.5               5.5                5.0  \n3                        8.0               7.0                7.5  \n4                        6.0               6.0                5.5  \n...                      ...               ...                ...  \n9907                     7.0               6.5                6.5  \n9908                     7.0               6.5                6.5  \n9909                     4.0               4.0                4.0  \n9910                     7.0               6.5                6.0  \n9911                     7.0               6.5                6.0  \n\n[9912 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>essay</th>\n      <th>task_achievement</th>\n      <th>coherence_and_cohesion</th>\n      <th>lexical_resource</th>\n      <th>grammatical_range</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Young people who commit crimes should be treat...</td>\n      <td>Deciding to choose among the potential ways of...</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>6.5</td>\n      <td>6.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Young people who commit crimes should be treat...</td>\n      <td>In this modern era, youngsters who commit offe...</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Young people who commit crimes should be treat...</td>\n      <td>In this modern era, youngsters who commit offe...</td>\n      <td>6.0</td>\n      <td>5.5</td>\n      <td>5.5</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Young people who commit crimes should be treat...</td>\n      <td>It is suggested that punishments for immature ...</td>\n      <td>7.5</td>\n      <td>8.0</td>\n      <td>7.0</td>\n      <td>7.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Young people who commit crimes should be treat...</td>\n      <td>There is a controversial dispute about whether...</td>\n      <td>6.5</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>5.5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9907</th>\n      <td>The best way to teach children to cooperate is...</td>\n      <td>It is proved that sports activities at school ...</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>6.5</td>\n      <td>6.5</td>\n    </tr>\n    <tr>\n      <th>9908</th>\n      <td>The best way to teach children to cooperate is...</td>\n      <td>Most people suggest that the prime way to teac...</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>6.5</td>\n      <td>6.5</td>\n    </tr>\n    <tr>\n      <th>9909</th>\n      <td>The best way to teach children to cooperate is...</td>\n      <td>Few argue that, the best way is teachers train...</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>9910</th>\n      <td>In today's world, people spend a lot of money ...</td>\n      <td>Nowadays people tend to invest huge amounts of...</td>\n      <td>6.5</td>\n      <td>7.0</td>\n      <td>6.5</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>9911</th>\n      <td>Some people think the main purpose of schools ...</td>\n      <td>The role of schools and the education system a...</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>6.5</td>\n      <td>6.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>9912 rows Ã— 6 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# --- 2. Imputasi Missing Value ---\nprint(\"\\n--- Imputasi Missing Value pada Kolom Target ---\")\ntarget_columns = ['task_achievement', 'coherence_and_cohesion', 'lexical_resource', 'grammatical_range']\nimputer = SimpleImputer(strategy='mean')\ndf_train[target_columns] = imputer.fit_transform(df_train[target_columns])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T02:37:01.621163Z","iopub.execute_input":"2025-08-13T02:37:01.621414Z","iopub.status.idle":"2025-08-13T02:37:01.639355Z","shell.execute_reply.started":"2025-08-13T02:37:01.621391Z","shell.execute_reply":"2025-08-13T02:37:01.638663Z"}},"outputs":[{"name":"stdout","text":"\n--- Imputasi Missing Value pada Kolom Target ---\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# --- 3. Tokenisasi dengan BERT ---\nprint(\"\\n--- Tokenisasi dengan BERT ---\")\ntokenizer = RobertaTokenizer.from_pretrained('roberta-base')\nMAX_LENGTH = 256  # Panjang maksimal token, sesuaikan jika esai Anda sangat panjang\n\n# Tokenisasi data training\ntokenized_train = tokenizer(\n    df_train['essay'].tolist(),\n    padding=True,\n    truncation=True,\n    max_length=MAX_LENGTH,\n    return_tensors='pt'\n)\n\n# Tokenisasi data test\ntokenized_test = tokenizer(\n    df_test['essay'].tolist(),\n    padding=True,\n    truncation=True,\n    max_length=MAX_LENGTH,\n    return_tensors='pt'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T02:37:01.640109Z","iopub.execute_input":"2025-08-13T02:37:01.640379Z","iopub.status.idle":"2025-08-13T02:37:29.883374Z","shell.execute_reply.started":"2025-08-13T02:37:01.640356Z","shell.execute_reply":"2025-08-13T02:37:29.882761Z"}},"outputs":[{"name":"stdout","text":"\n--- Tokenisasi dengan BERT ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6ccdb8d7fa5490685303c1ef9db5a80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70be0d041e9341bcacf80cc2ed4031c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"285d38ad609c4ddfb13458ec27453060"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"455117c0cf724ee48c566fe8a6890bea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b36f951171f9441ba9d3e5361e76e55f"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# --- 4. Persiapan Data untuk PyTorch ---\nprint(\"\\n--- Persiapan Data untuk PyTorch ---\")\ntrain_labels = torch.tensor(df_train[target_columns].values, dtype=torch.float32)\ntrain_dataset = TensorDataset(tokenized_train['input_ids'], tokenized_train['attention_mask'], train_labels)\n\ntest_dataset = TensorDataset(tokenized_test['input_ids'], tokenized_test['attention_mask'])\n\nBATCH_SIZE = 16  # Ukuran batch, sesuaikan dengan kapasitas GPU\ntrain_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE)\ntest_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=BATCH_SIZE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T02:37:29.884210Z","iopub.execute_input":"2025-08-13T02:37:29.884482Z","iopub.status.idle":"2025-08-13T02:37:29.894357Z","shell.execute_reply.started":"2025-08-13T02:37:29.884447Z","shell.execute_reply":"2025-08-13T02:37:29.893472Z"}},"outputs":[{"name":"stdout","text":"\n--- Persiapan Data untuk PyTorch ---\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# --- 5. Definisi Model untuk Multi-Target Regresi ---\nprint(\"\\n--- Definisi Model RoBERTa untuk Multi-Target Regresi ---\")\nfrom transformers import RobertaModel\n\nclass RobertaForMultiTargetRegression(torch.nn.Module):\n    def __init__(self, num_labels):\n        super(RobertaForMultiTargetRegression, self).__init__()\n        # Menggunakan RobertaModel sebagai base feature extractor\n        self.roberta = RobertaModel.from_pretrained('roberta-base')\n        self.dropout = torch.nn.Dropout(0.1)\n        # Menambahkan lapisan regresi baru di atas output RoBERTa\n        self.regressor = torch.nn.Linear(self.roberta.config.hidden_size, num_labels)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n        # Mengambil hidden state dari [CLS] token, yang merepresentasikan seluruh kalimat\n        cls_output = outputs.last_hidden_state[:, 0, :]\n        cls_output = self.dropout(cls_output)\n        logits = self.regressor(cls_output)\n        return logits\n\n# Inisialisasi model, optimizer, dan loss function\nnum_labels = len(target_columns)\nmodel = RobertaForMultiTargetRegression(num_labels)\noptimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\nloss_fn = torch.nn.MSELoss()\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T02:37:29.895196Z","iopub.execute_input":"2025-08-13T02:37:29.896253Z","iopub.status.idle":"2025-08-13T02:37:33.059598Z","shell.execute_reply.started":"2025-08-13T02:37:29.896227Z","shell.execute_reply":"2025-08-13T02:37:33.058847Z"}},"outputs":[{"name":"stdout","text":"\n--- Definisi Model RoBERTa untuk Multi-Target Regresi ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dabe59173464b34821ec5d82f72c3eb"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"RobertaForMultiTargetRegression(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): RobertaPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (regressor): Linear(in_features=768, out_features=4, bias=True)\n)"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# --- 6. Pelatihan Model (Fine-Tuning) ---\nprint(\"\\n--- Memulai Pelatihan Model (Fine-Tuning) ---\")\nEPOCHS = 15 # Jumlah epoch, 3-5 adalah nilai yang umum\nmodel.train()\n\nfor epoch in range(EPOCHS):\n    total_loss = 0\n    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n        input_ids, attention_mask, labels = batch \n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        labels = labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(input_ids, attention_mask)\n        \n        loss = loss_fn(outputs, labels)\n        total_loss += loss.item()\n         \n        loss.backward()\n        optimizer.step()\n        \n    avg_loss = total_loss / len(train_dataloader)\n    print(f\"Loss di akhir Epoch {epoch+1}: {avg_loss:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T02:37:33.060337Z","iopub.execute_input":"2025-08-13T02:37:33.060575Z"}},"outputs":[{"name":"stdout","text":"\n--- Memulai Pelatihan Model (Fine-Tuning) ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1/8:   0%|          | 0/620 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f899da2efe174063908643a5f859e2f1"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"print(\"\\n--- Memulai Prediksi pada Data Test ---\")\nmodel.eval()\ntest_predictions = []\nwith torch.no_grad():\n    for batch in tqdm(test_dataloader, desc=\"Predicting\"):\n        input_ids, attention_mask = batch\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        \n        outputs = model(input_ids, attention_mask)\n        test_predictions.extend(outputs.cpu().numpy())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 8. Simpan Hasil Prediksi ke File Excel ---\nprint(\"\\n--- Menyimpan Hasil Prediksi ke csv ---\")\npredicted_df = pd.DataFrame(test_predictions, columns=[f'predicted_{col}' for col in target_columns])\nfinal_predictions = pd.concat([df_test.reset_index(drop=True), predicted_df], axis=1)\nfinal_predictions.to_csv('hasil_prediksi_esay_bert.csv', index=False)\n\nprint(\"\\nProses selesai. File 'hasil_prediksi_esay_roberta.csv' berhasil dibuat.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}