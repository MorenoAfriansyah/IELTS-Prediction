{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12716504,"sourceType":"datasetVersion","datasetId":8037313}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom transformers import BertTokenizer, BertForSequenceClassification\nfrom torch.optim import AdamW\nfrom sklearn.metrics import mean_squared_error\nfrom tqdm.auto import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 1. Muat data ---\nprint(\"--- Memuat Data ---\")\ndf_train = pd.read_csv('/kaggle/input/bdc-dataset/df_train (1).csv')\ndf_test = pd.read_csv('/kaggle/input/bdc-dataset/df_test (1).csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 2. Imputasi Missing Value ---\nprint(\"\\n--- Imputasi Missing Value pada Kolom Target ---\")\ntarget_columns = ['task_achievement', 'coherence_and_cohesion', 'lexical_resource', 'grammatical_range']\nimputer = SimpleImputer(strategy='mean')\ndf_train[target_columns] = imputer.fit_transform(df_train[target_columns])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 3. Tokenisasi dengan BERT ---\nprint(\"\\n--- Tokenisasi dengan BERT ---\")\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nMAX_LENGTH = 256  # Panjang maksimal token, sesuaikan jika esai Anda sangat panjang\n\n# Tokenisasi data training\ntokenized_train = tokenizer(\n    df_train['essay'].tolist(),\n    padding=True,\n    truncation=True,\n    max_length=MAX_LENGTH,\n    return_tensors='pt'\n)\n\n# Tokenisasi data test\ntokenized_test = tokenizer(\n    df_test['essay'].tolist(),\n    padding=True,\n    truncation=True,\n    max_length=MAX_LENGTH,\n    return_tensors='pt'\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 4. Persiapan Data untuk PyTorch ---\nprint(\"\\n--- Persiapan Data untuk PyTorch ---\")\ntrain_labels = torch.tensor(df_train[target_columns].values, dtype=torch.float32)\ntrain_dataset = TensorDataset(tokenized_train['input_ids'], tokenized_train['attention_mask'], train_labels)\n\ntest_dataset = TensorDataset(tokenized_test['input_ids'], tokenized_test['attention_mask'])\n\nBATCH_SIZE = 16  # Ukuran batch, sesuaikan dengan kapasitas GPU\ntrain_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE)\ntest_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=BATCH_SIZE)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 5. Definisi Model BERT untuk Multi-Target Regresi ---\nprint(\"\\n--- Definisi Model BERT untuk Multi-Target Regresi ---\")\nclass BertForMultiTargetRegression(torch.nn.Module):\n    def __init__(self, num_labels):\n        super(BertForMultiTargetRegression, self).__init__()\n        # Menggunakan BertForSequenceClassification, tapi kita akan ubah head-nya\n        self.bert = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n        self.regressor = torch.nn.Linear(self.bert.config.hidden_size, num_labels)\n        self.bert.classifier = self.regressor # Ganti lapisan classifier bawaan dengan regressor kita\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=False)\n        logits = outputs.logits\n        return logits\n\n# Inisialisasi model, optimizer, dan loss function\nnum_labels = len(target_columns)\nmodel = BertForMultiTargetRegression(num_labels)\noptimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\nloss_fn = torch.nn.MSELoss()\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 6. Pelatihan Model (Fine-Tuning) ---\nprint(\"\\n--- Memulai Pelatihan Model (Fine-Tuning) ---\")\nEPOCHS = 8 # Jumlah epoch, 3-5 adalah nilai yang umum\nmodel.train()\n\nfor epoch in range(EPOCHS):\n    total_loss = 0\n    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n        input_ids, attention_mask, labels = batch \n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        labels = labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(input_ids, attention_mask)\n        \n        loss = loss_fn(outputs, labels)\n        total_loss += loss.item()\n         \n        loss.backward()\n        optimizer.step()\n        \n    avg_loss = total_loss / len(train_dataloader)\n    print(f\"Loss di akhir Epoch {epoch+1}: {avg_loss:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 7. Prediksi pada Data Test ---\nprint(\"\\n--- Memulai Prediksi pada Data Test ---\")\nmodel.eval()\ntest_predictions = []\nwith torch.no_grad():\n    for batch in tqdm(test_dataloader, desc=\"Predicting\"):\n        input_ids, attention_mask = batch\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        \n        outputs = model(input_ids, attention_mask)\n        test_predictions.extend(outputs.cpu().numpy())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 8. Simpan Hasil Prediksi ke File Excel ---\nprint(\"\\n--- Menyimpan Hasil Prediksi ke Excel ---\")\npredicted_df = pd.DataFrame(test_predictions, columns=[f'predicted_{col}' for col in target_columns])\nfinal_predictions = pd.concat([df_test.reset_index(drop=True), predicted_df], axis=1)\nfinal_predictions.to_excel('hasil_prediksi_esay_bert.xlsx', index=False)\n\nprint(\"\\nProses selesai. File 'hasil_prediksi_esay_bert.xlsx' berhasil dibuat.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}